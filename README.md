
### _We develop a Toolbox-[BoxInstSeg](https://github.com/LiWentomng/BoxInstSeg) for box-supervised instance segmentation. More codes (e.g. BoxInst, DiscoBox, Box2Mask) will be updated in it._




This rep is for **Box-supervised Instance Segmentation with Level Set Evolution(ECCV2022)**
 > Wentong Li, Wenyu Liu, [Jianke Zhu](https://person.zju.edu.cn/jkzhu), Miaomiao Cui, [Xiansheng Hua](https://scholar.google.com/citations?user=6G-l4o0AAAAJ&hl=zh-CN&oi=ao), [Lei Zhang](http://www4.comp.polyu.edu.hk/~cslzhang/) 

[Paper](./docs/BoxLevelset-ECCV2022.pdf) ([Arxiv](https://arxiv.org/abs/2207.09055))

### Installation

This implementation is based on [MMdetection](https://github.com/open-mmlab/mmdetection).
Please refer to [install.md](./docs/install.md) for detailed installation.


### Getting Started 
Please see [getting_started.md](./docs/get_started.md) for models `training` and `inference`.

### Performance

### Models
 * The following models are trained with Telsa V100 GPU. 
 * The pretrained models are in GoogleDriver.

#### Mask AP Results on Pascal VOC val
|     Backbone    |  schd | Models | GPUs | AP  | AP_25 | AP_50 | AP_70 | AP_75 | 
|:---------------:|--------|--------|:----:|:----:|:-----:|:-----:|:--------:|:---------:|
|    ResNet-50    |   3x   |[model](https://drive.google.com/file/d/1Yl4QCRx_VKY_OvEI6sz36BI88sSOWWhu/view?usp=sharing) |  4 |36.5 |  76.8 |  64.2 |   44.8   |    36.4   |  
|   ResNet-101    |   3x   |[model](https://drive.google.com/file/d/1gMWGxmPyHFyxR0re3lHbMjxl3xvPvWeh/view?usp=sharing) |  4 |38.3 |  77.9 |  66.3 |   46.4   |    38.7   | 


#### Mask AP Results on COCO 2017
|     Backbone    |  schd  |Models | GPUs | AP(val)  | AP(test-dev) |
|:---------------:|--------|--------|:----:|:----:|:-----:|
|    ResNet-50    |  3x    |[model](https://drive.google.com/file/d/1R-2s5wh-Rj82yieFcXa5_T9gW9oB29dj/view?usp=sharing)  |  8  |31.4 |  31.7 | 
|   ResNet-101    |  3x    |[model](https://drive.google.com/file/d/1mZ5PBRINlfhHPxzSPvace65Qs4lzG2kL/view?usp=sharing)  |  8  |33.0 |  33.4 | 
|   ResNet-101-DCN|  3x    |[model](https://drive.google.com/file/d/1aZN9CUd2flcsW_KewWUgerjF0AjWszCB/view?usp=sharing)  |  8  |35.0 |  35.4 | 
 
 Note: 
 * Following [BBTP](https://github.com/chengchunhsu/WSIS_BBTP) and [DiscoBox](https://github.com/NVlabs/DiscoBox), the Pascal VOC is aumented Pascal VOC([data link](https://drive.google.com/file/d/16Mz13NSZBbhwPuRxiwi7ZA2Qvt9DaKtN/view?usp=sharing)) with SBD. We recomment the users to train the Pascal VOC first to validate the performance with  ~14 hours training time. 
 * Training COCO with 3x needs about 4 days. 
 
  #### Mask AP Results on iSAID val
|     Backbone    |  schd | Models | GPUs | input| AP  | AP_50 | AP_75 |  
|:---------------:|--------|--------|:----:|:----:|:----:|:-----:|:-----:|
|    ResNet-50    |   1x   |[model](https://drive.google.com/file/d/1RjVP1CwHlqnpPd2G1vnIMSO_CT2hFzdI/view?usp=sharing) |  4 | 800*800 | 24.3 |  48.1 |  20.7 | 

Note: 
 * The high-resolution images of isaid are splitted into `800*800` patches. 
 * The input size of network is also set to 800*800.
 * The train subset is used for model training, the val subset is for performance evaluation. 
 
 
 #### Visual Results on General Scene
 
 <img src="./docs/vis_figure.png" width="800px">

 #### Visual Results on iSAID (remote sensing)
<img src="./docs/vis_isaid.png" width="800px">

* The bounding boxes are generated by the mask predictions.

 Please run the following script to get more visual results. 
 ```
    python tools/test.py configs/boxlevelset/config-xxx.py work_dirs/xxx.pth  --show-dir show_dirs/
 ``` 
 
### Citation
```BibTeX
@article{li2022boxlevelset,
  title={Box-supervised Instance Segmentation with Level Set Evolution},
  author={Wentong Li, Wenyu Liu, Jianke Zhu, Miaomiao Cui, Xiansheng Hua, Lei Zhang},
  journal={ECCV2022},
  year={2022}
}
```

###  Acknowledgements

[SOLO](https://github.com/WXinlong/SOLO)

[AdelaiDet](https://github.com/aim-uofa/AdelaiDet)

### License

For academic use, this project is licensed under the Apache License 2.0. For commercial use, please contact the authors.




